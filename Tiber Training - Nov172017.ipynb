{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs of NYC\n",
    "## Tiber Training November 17th, 2017\n",
    "\n",
    "WNYP provides a great resource of [dogs of New York City names](https://project.wnyc.org/dogs-of-nyc/) that seems like a great place to start our analysis!\n",
    "\n",
    "**[Pandas](http://pandas.pydata.org/)** is the package we're going to be using the most of!\n",
    "\n",
    "##### Pandas? Pandas!\n",
    "\n",
    "![Image of red panda](https://i.pinimg.com/736x/57/49/cb/5749cb63e52dd8ce3a0376ddd185cdaf--adorable-pets-baby-animals-adorable.jpg)\n",
    "\n",
    ">\"What problem does pandas solve?\n",
    "\n",
    ">Python has long been great for data munging and preparation, but less so for data analysis and modeling. pandas helps fill this gap, enabling you to carry out your entire data analysis workflow in Python without having to switch to a more domain specific language like R.\n",
    "\n",
    ">Combined with the excellent IPython toolkit and other libraries, the environment for doing data analysis in Python excels in performance, productivity, and the ability to collaborate.\n",
    "\n",
    ">pandas does not implement significant modeling functionality outside of linear and panel regression; for this, look to statsmodels and scikit-learn. More work is still needed to make Python a first class statistical modeling environment, but we are well on our way toward that goal.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Library Highlights\n",
    "\n",
    "![Image of panda library](https://farm8.staticflickr.com/7397/12824365945_bca225debe_z.jpg)\n",
    "\n",
    "\n",
    "> - A fast and efficient DataFrame object for data manipulation with integrated indexing;\n",
    "> - Tools for reading and writing data between in-memory data structures and different formats: CSV and text files, Microsoft Excel, SQL databases, and the fast HDF5 format;\n",
    "> - Intelligent data alignment and integrated handling of missing data: gain automatic label-based alignment in computations and easily manipulate messy data into an orderly form;\n",
    "> - Flexible reshaping and pivoting of data sets;\n",
    "> - Intelligent label-based slicing, fancy indexing, and subsetting of large data sets;\n",
    "> - Columns can be inserted and deleted from data structures for size mutability;\n",
    "> - Aggregating or transforming data with a powerful group by engine allowing split-apply-combine operations on data sets;\n",
    "> - High performance merging and joining of data sets;\n",
    "> - Hierarchical axis indexing provides an intuitive way of working with high-dimensional data in a lower-dimensional data structure;\n",
    "> - Time series-functionality: date range generation and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging. Even create domain-specific time offsets and join time series without losing data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay, let's start importing things:\n",
    "\n",
    "matplotlib is a great plotting library\n",
    "\n",
    "`plt.style.use('ggplot')` adds a customised style to my plots\n",
    "\n",
    "`% matplotlib inline` this makes sure my plots show up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Again: Hadley Wickham's approach to EDA:  \n",
    "![image of the data flow showing visualization as an exploratory and iterative process](http://benbestphd.com/images/r4ds_data-science.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### The goal of EDA is to discover patterns in data. This is a fundamental stepping stone towards predictive modelling, or an end goal in itself. \n",
    "\n",
    "Tips for good EDA:\n",
    "- Understand the context. \n",
    "- Use graphical representations of data\n",
    "- Develop models in an iterative process of tentative model specification and residual assessment \n",
    "- Question the data: Who collected it? Who is distributing it? Do all of the patterns make sense to what you know about the world? If they don’t, go back and look more closely at your data.\n",
    "- Don’t think of EDA as an initial step. \n",
    "\n",
    "\n",
    "\n",
    "You can use `pd.read_csv` to point towards files on site or on the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogurl = 'https://raw.githubusercontent.com/aapeebles/tiber-Nov172017/master/Dogs%20of%20NYC%20-%20WNYC.csv'\n",
    "\n",
    "df = pd.read_csv(dogurl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## looking at the data\n",
    "\n",
    "Top of the data is `df.head()` and you can ask for the top 20, 10, 32 by putting a number in the `()`\n",
    "You see the bottom with `df.tail()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look for at the last 12 records in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is we want to look at the columns without opening the file?\n",
    "\n",
    "`df.columns`\n",
    "\n",
    "### How can you see what type of variable each column is?\n",
    "\n",
    "`df.dtypes()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how many total rows and columns we have\n",
    "\n",
    "`df.shape`\n",
    "\n",
    "### And how many of those rows are missing values\n",
    "\n",
    "`df.isnull().sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get rid of some duplicates by making everything lower case\n",
    "\n",
    "using `str.lower()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dog_name = df.dog_name.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check what names are most common\n",
    "\n",
    "value_counts creates a series of the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.dog_name.value_counts()[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many dogs are there in each bourough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many Unique names are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dog_name.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many Unique dog BREEDS are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the top five breeds of dogs\n",
    "df.breed.value_counts()[:5].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crosstab\n",
    "\n",
    "Pandas has a great function called [crosstab](https://chrisalbon.com/python/pandas_crosstabs.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick comparison of what breeds are neutered vs. not\n",
    "pd.crosstab(df.breed,df.neutered).sort_values('Yes', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many Trained dogs are there per borough?\n",
    "\n",
    "to figure this out, let's first convert the 'guard_or_trained' column to numbers so it's easier to sum up. \n",
    "\n",
    "one of the ways we can do that is to create a dictionary where we assign a number to each string\n",
    "\n",
    "`boolean = {'No': 0, 'Yes': 1}`\n",
    "\n",
    "we can then map those values to the 'trained' column so the string values are replaced with the numbers we coded\n",
    "\n",
    "`df['trained'] = df.guard_or_trained.map(boolean)`\n",
    "\n",
    "\n",
    "run the code and then check if it worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby\n",
    "\n",
    "[Groupby](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html) is a powerful aggregating tool in pandas.\n",
    "\n",
    "In the code bellow you have the following parts:\n",
    "\n",
    "`df.groupby('borough').trained.sum().sort_values(ascending=False)`\n",
    "\n",
    "- **df** is the dataframe you referencing\n",
    "- **groupby** is the function of pandas you are calling\n",
    "- **borough** is the variable WITHIN df you are grouping by\n",
    "- **trained** is what you are actually counting\n",
    "- **sum** is how you are aggregating - and this is why we pulling in numpy to have the sum function\n",
    "- **sort_values** tells python how you want the aggregation sorted\n",
    "\n",
    "Okay, run the code and see what you get!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat with Neutered\n",
    "\n",
    "Do the same steps again, but counting how many are neutered per neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Stuck on what to do next? Here's a really thorough Pandas tutorial on the different ways in which you can approach the dataset: https://pandas.pydata.org/pandas-docs/stable/tutorials.html\n",
    "\n",
    "### Next steps:\n",
    "- There are a bunch of other datasets at http://opendata.dc.gov/ that you can also look at. I've included some datasets on awards given out by ward in this repo\n",
    "- Want to explore more numerical datasets? Here's a great tutorial that looks at life expectancies around the world: https://github.com/alfredessa/awesomedata.science/blob/master/2.0PandasIntro/Intro.Pandas.EDA.ipynb\n",
    "- Want to dive into the visualization aspect of EDA? This isn't a tutorial as much as a walk-through of Hadley Wickham's thought process. Still worth it: https://www.youtube.com/watch?v=ZdPNBF6GWBw\n",
    "- Want more datasets to dig into? Jeremy Singer-Vine from BuzzFeed puts out a regular newsletter called Data is Plural. You can sign up and access the archives here: https://tinyletter.com/data-is-plural; Kaggle (the data science competition website) also has a tonne of great (clean!) datasets available: https://www.kaggle.com/datasets. Their head of data preparation, Rachael Tatman, also has a fantastic newsletter where she shares linguistic datasets: http://rachaeltatman.com/ (she also live codes on Friday nights!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
